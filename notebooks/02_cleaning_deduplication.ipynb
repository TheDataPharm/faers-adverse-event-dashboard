{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "917b239a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Demographics data...\n",
      "Loading Drug data...\n",
      "--- LOAD COMPLETE ---\n",
      "Total Demographic Rows: 2,048,518\n",
      "Total Drug Rows:        9,923,900\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: SETUP\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc # Garbage Collector to free up memory\n",
    "\n",
    "# Define paths\n",
    "PROCESSED_DIR = r\"C:\\Users\\findo\\OneDrive\\Desktop\\faers-dashboard\\data\\processed\"\n",
    "\n",
    "# 1. Load the \"Anchor\" Table: Demographics\n",
    "print(\"Loading Demographics data...\")\n",
    "df_demo = pd.read_parquet(os.path.join(PROCESSED_DIR, 'all_demo.parquet'))\n",
    "\n",
    "# 2. Load the Drug Table (we need this to find our specific drugs)\n",
    "print(\"Loading Drug data...\")\n",
    "df_drug = pd.read_parquet(os.path.join(PROCESSED_DIR, 'all_drug.parquet'))\n",
    "\n",
    "print(f\"--- LOAD COMPLETE ---\")\n",
    "print(f\"Total Demographic Rows: {len(df_demo):,}\")\n",
    "print(f\"Total Drug Rows:        {len(df_drug):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baa132a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before dedup: 2,048,518\n",
      "Rows after dedup:  1,826,300\n",
      "Removed 222,218 duplicate versions.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CELL 2: DEDUPLICATION\n",
    "\n",
    "print(f\"Rows before dedup: {len(df_demo):,}\")\n",
    "\n",
    "# 1. Convert caseid and caseversion to numeric to ensure correct sorting\n",
    "# (Sometimes they load as strings, which sort incorrectly like \"10\" < \"2\")\n",
    "df_demo['caseid'] = pd.to_numeric(df_demo['caseid'], errors='coerce')\n",
    "df_demo['caseversion'] = pd.to_numeric(df_demo['caseversion'], errors='coerce')\n",
    "\n",
    "# 2. Sort by Case ID and Version (Ascending)\n",
    "# So the highest version is at the bottom for each case\n",
    "df_demo.sort_values(by=['caseid', 'caseversion'], ascending=[True, True], inplace=True)\n",
    "\n",
    "# 3. Keep only the LAST occurrence of each caseid\n",
    "df_demo_clean = df_demo.drop_duplicates(subset=['caseid'], keep='last').copy()\n",
    "\n",
    "print(f\"Rows after dedup:  {len(df_demo_clean):,}\")\n",
    "print(f\"Removed {len(df_demo) - len(df_demo_clean):,} duplicate versions.\")\n",
    "\n",
    "# Free up memory by deleting the messy original\n",
    "del df_demo\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4367485d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for GLP-1 cases...\n",
      "--- FILTER RESULTS ---\n",
      "Found 89,571 rows matching GLP-1s (Primary Suspect).\n",
      "Unique Cases (PrimaryIDs): 89,567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CELL 3: IDENTIFY TARGET DRUGS (GLP-1s)\n",
    "\n",
    "# 1. Clean the drug names for searching (lowercase, strip spaces)\n",
    "df_drug['drugname_clean'] = df_drug['drugname'].str.lower().str.strip()\n",
    "\n",
    "# 2. Define the Target List (Brands + Generics)\n",
    "\n",
    "target_pattern = 'ozempic|wegovy|rybelsus|semaglutide|mounjaro|zepbound|tirzepatide'\n",
    "\n",
    "# 3. Filter the Drug Table\n",
    "# Condition A: The drug name matches our pattern\n",
    "# Condition B: The drug is the \"Primary Suspect\" (PS)\n",
    "print(\"Searching for GLP-1 cases...\")\n",
    "mask_target = (\n",
    "    df_drug['drugname_clean'].str.contains(target_pattern, na=False, regex=True) & \n",
    "    (df_drug['role_cod'] == 'PS')\n",
    ")\n",
    "\n",
    "df_drug_glp1 = df_drug[mask_target].copy()\n",
    "\n",
    "# 4. Get the list of relevant Case IDs\n",
    "# These are the IDs we will use to fetch Demographics and Reactions\n",
    "relevant_ids = df_drug_glp1['primaryid'].unique()\n",
    "\n",
    "print(f\"--- FILTER RESULTS ---\")\n",
    "print(f\"Found {len(df_drug_glp1):,} rows matching GLP-1s (Primary Suspect).\")\n",
    "print(f\"Unique Cases (PrimaryIDs): {len(relevant_ids):,}\")\n",
    "\n",
    "# Clean up memory\n",
    "del df_drug\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db34328a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PREPARING SUB-TABLES ---\n",
      "Target Demographics: 87,462\n",
      "Loading Outcomes...\n",
      "Flagging Serious Outcomes...\n",
      "Loading Reactions...\n",
      "Target Reactions: 215,660\n",
      "\n",
      "--- EXECUTING MERGE ---\n",
      "--- FINAL DATASET ---\n",
      "Total Rows: 207,725\n",
      "Columns: ['primaryid', 'caseid', 'event_dt', 'age', 'age_cod', 'sex', 'wt', 'rept_dt', 'occr_country', 'drugname_clean', 'death', 'serious', 'hospital', 'pt']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CELL 4: LOADING & MERGING OTHER TABLES\n",
    "\n",
    "print(\"--- PREPARING SUB-TABLES ---\")\n",
    "\n",
    "# 1. Filter DEMO to just our target 89k cases\n",
    "# We pick specific columns to keep the file size small\n",
    "cols_demo = ['primaryid', 'caseid', 'event_dt', 'age', 'age_cod', 'sex', 'wt', 'rept_dt', 'occr_country']\n",
    "df_demo_target = df_demo_clean[df_demo_clean['primaryid'].isin(relevant_ids)][cols_demo].copy()\n",
    "print(f\"Target Demographics: {len(df_demo_target):,}\")\n",
    "\n",
    "# 2. Load and Filter OUTCOMES (OUTC)\n",
    "# We handle this carefully to avoid duplicates\n",
    "print(\"Loading Outcomes...\")\n",
    "df_outc = pd.read_parquet(os.path.join(PROCESSED_DIR, 'all_outc.parquet'))\n",
    "df_outc_target = df_outc[df_outc['primaryid'].isin(relevant_ids)].copy()\n",
    "\n",
    "# Feature Engineering: Create simple flags instead of keeping raw rows\n",
    "# If a case has 'DE' in the outc_cod column, they died.\n",
    "# If 'HO', they were hospitalized.\n",
    "print(\"Flagging Serious Outcomes...\")\n",
    "outc_flags = df_outc_target.groupby('primaryid')['outc_cod'].apply(set).to_frame('outc_set')\n",
    "\n",
    "# Create binary columns (0 or 1)\n",
    "outc_flags['death'] = outc_flags['outc_set'].apply(lambda x: 1 if 'DE' in x else 0)\n",
    "outc_flags['serious'] = outc_flags['outc_set'].apply(lambda x: 1 if any(c in x for c in ['DE', 'HO', 'LT', 'OT']) else 0)\n",
    "outc_flags['hospital'] = outc_flags['outc_set'].apply(lambda x: 1 if 'HO' in x else 0)\n",
    "\n",
    "# Drop the set column, we just need the flags\n",
    "outc_flags = outc_flags[['death', 'serious', 'hospital']]\n",
    "\n",
    "# 3. Load and Filter REACTIONS (REAC)\n",
    "print(\"Loading Reactions...\")\n",
    "df_reac = pd.read_parquet(os.path.join(PROCESSED_DIR, 'all_reac.parquet'))\n",
    "df_reac_target = df_reac[df_reac['primaryid'].isin(relevant_ids)][['primaryid', 'pt']].copy()\n",
    "print(f\"Target Reactions: {len(df_reac_target):,}\")\n",
    "\n",
    "print(\"\\n--- EXECUTING MERGE ---\")\n",
    "# Merge 1: Demo + Drug Information (Indication/Name)\n",
    "# We take the drug info from our filtered drug table\n",
    "df_step1 = pd.merge(df_demo_target, df_drug_glp1[['primaryid', 'drugname_clean']], on='primaryid', how='left')\n",
    "\n",
    "# Merge 2: Add Outcome Flags\n",
    "df_step2 = pd.merge(df_step1, outc_flags, on='primaryid', how='left')\n",
    "# Fill NaN outcomes with 0 (Non-serious)\n",
    "df_step2[['death', 'serious', 'hospital']] = df_step2[['death', 'serious', 'hospital']].fillna(0).astype(int)\n",
    "\n",
    "# Merge 3: Add Reactions (This expands the rows!)\n",
    "df_final = pd.merge(df_step2, df_reac_target, on='primaryid', how='inner')\n",
    "\n",
    "print(f\"--- FINAL DATASET ---\")\n",
    "print(f\"Total Rows: {len(df_final):,}\")\n",
    "print(\"Columns:\", df_final.columns.tolist())\n",
    "\n",
    "# Clean up\n",
    "del df_outc, df_reac, df_demo_clean\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7c19903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FEATURE ENGINEERING ---\n",
      "--- EXPORTING ---\n",
      "SUCCESS! Dashboard data saved to: C:\\Users\\findo\\OneDrive\\Desktop\\faers-dashboard\\data\\processed\\faers_glp1_final.csv\n",
      "Preview of final columns:\n",
      "   primaryid sex      age_group indication_group  \\\n",
      "0  157323573   F  Adult (18-64)         Diabetes   \n",
      "1  157323573   F  Adult (18-64)         Diabetes   \n",
      "2  157323573   F  Adult (18-64)         Diabetes   \n",
      "3  157323573   F  Adult (18-64)         Diabetes   \n",
      "4  157323573   F  Adult (18-64)         Diabetes   \n",
      "\n",
      "                                pt  serious  \n",
      "0  Altered visual depth perception        0  \n",
      "1             Heart rate increased        0  \n",
      "2          Blood glucose increased        0  \n",
      "3                 Feeling abnormal        0  \n",
      "4                   Vision blurred        0  \n"
     ]
    }
   ],
   "source": [
    "# CELL 5: CLEANING & EXPORT\n",
    "\n",
    "print(\"--- FEATURE ENGINEERING ---\")\n",
    "\n",
    "# 1. Normalize Age to Years\n",
    "# FAERS uses codes: YR=Year, MON=Month, WK=Week, DY=Day\n",
    "def normalize_age(row):\n",
    "    age = row['age']\n",
    "    unit = row['age_cod']\n",
    "    \n",
    "    # Return NaN if empty\n",
    "    if pd.isna(age) or pd.isna(unit):\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        age = float(age)\n",
    "    except:\n",
    "        return None\n",
    "        \n",
    "    if unit == 'YR':\n",
    "        return age\n",
    "    elif unit == 'MON':\n",
    "        return age / 12\n",
    "    elif unit == 'WK':\n",
    "        return age / 52\n",
    "    elif unit == 'DY':\n",
    "        return age / 365\n",
    "    elif unit == 'DEC': # Decade\n",
    "        return age * 10\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df_final['age_years'] = df_final.apply(normalize_age, axis=1)\n",
    "\n",
    "# Filter out impossible ages (e.g., typos like 999 years)\n",
    "df_final.loc[df_final['age_years'] > 110, 'age_years'] = None\n",
    "\n",
    "# Create Age Groups (Recruiters love bins)\n",
    "bins = [0, 18, 65, 110]\n",
    "labels = ['Pediatric (<18)', 'Adult (18-64)', 'Elderly (65+)']\n",
    "df_final['age_group'] = pd.cut(df_final['age_years'], bins=bins, labels=labels)\n",
    "\n",
    "# 2. Infer Indication (Diabetes vs. Obesity) based on Brand Name\n",
    "# This creates the \"Business Insight\" column\n",
    "def infer_indication(drug_name):\n",
    "    if pd.isna(drug_name): return 'Unknown'\n",
    "    \n",
    "    name = drug_name.lower()\n",
    "    # Weight Loss Brands\n",
    "    if 'wegovy' in name or 'zepbound' in name:\n",
    "        return 'Obesity / Weight Loss'\n",
    "    # Diabetes Brands\n",
    "    elif 'ozempic' in name or 'mounjaro' in name or 'rybelsus' in name:\n",
    "        return 'Diabetes'\n",
    "    # Generic or Unspecified\n",
    "    else:\n",
    "        return 'Unspecified/Other'\n",
    "\n",
    "df_final['indication_group'] = df_final['drugname_clean'].apply(infer_indication)\n",
    "\n",
    "print(\"--- EXPORTING ---\")\n",
    "# 3. Save to CSV\n",
    "# This is the file you will connect to Tableau/Power BI\n",
    "output_path = os.path.join(PROCESSED_DIR, 'faers_glp1_final.csv')\n",
    "df_final.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"SUCCESS! Dashboard data saved to: {output_path}\")\n",
    "print(\"Preview of final columns:\")\n",
    "print(df_final[['primaryid', 'sex', 'age_group', 'indication_group', 'pt', 'serious']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb414d27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
